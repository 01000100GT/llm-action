


- 大模型主流应用RAG的介绍——从架构到技术细节：https://luxiangdong.com/2023/09/25/ragone/#/%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2
- 从 RAG 到 Self-RAG —— LLM 的知识增强：https://zhuanlan.zhihu.com/p/661465330
- 大模型检索增强生成（RAG）有哪些好用的技巧？：https://www.zhihu.com/question/625481187




-----

现在越来越多的实践者开始意识到一套向量数据库打天下的方案已经不够了，于是有了各种花式疗法，从构建索引到回复生成，可谓百花齐放，眼花缭乱：

内容切片不够好，容易切碎，于是有了段落智能划分；

向量生成的质量不可控，于是有了可根据不同QA场景动态生成向量的Instructor；

隐式的动态向量不够过瘾，再用HyDE做个中间层：先生成一些虚拟文档/假设文档再做召回，提升召回率；

如果向量这一路召回不够，再上关键词召回，传统BM25+向量HNSW融合各召回通路；

召回的太多容易干扰答案生成，探究一下Lost in the Middle，搞一搞trick，或者用LLMLingua压缩；

嫌召回太麻烦？直接扩到100k窗口全量怼进大模型，LongLoRA横空出世；

刚才提到的各个环节需要改进的点太多，懒得手工做，直接交给大模型，用Self-RAG替你完成每个步骤……




