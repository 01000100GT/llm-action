



https://github.com/nbasyl/LLM-FP4


LLM-FP4: 4-Bit Floating-Point Quantized Transformers 


ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats