
## 安装DeepSpeed
通过 pip 是最快捷的开始使用 DeepSpeed 的方式，这将安装最新版本的 DeepSpeed，不会与特定的 PyTorch 或 CUDA 版本绑定。DeepSpeed 包含若干个 C++/CUDA 扩展，我们通常称之为“ops”。默认情况下，所有这些 extensions/ops 将使用 torch 的 JIT C++ 扩展加载器即时构建（JIT）(https://pytorch.org/docs/stable/cpp_extension.html) ，该加载器依赖 ninja 在运行时进行动态链接。

```
pip install deepspeed
```

安装完DeepSpeed后，你可以使用 ds_report 或 python -m deepspeed.env_report 命令查看 DeepSpeed 环境报告，以验证你的安装并查看你的机器与哪些 ops 兼容。我们发现，在调试 DeepSpeed 安装或兼容性问题时，这个报告很有用


```
ds_report
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [OKAY]
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
async_io ............... [NO] ....... [OKAY]
cpu_adagrad ............ [NO] ....... [OKAY]
cpu_adam ............... [NO] ....... [OKAY]
fused_adam ............. [NO] ....... [OKAY]
fused_lamb ............. [NO] ....... [OKAY]
quantizer .............. [NO] ....... [OKAY]
random_ltd ............. [NO] ....... [OKAY]
 [WARNING]  please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [NO] ....... [NO]
spatial_inference ...... [NO] ....... [OKAY]
transformer ............ [NO] ....... [OKAY]
stochastic_transformer . [NO] ....... [OKAY]
transformer_inference .. [NO] ....... [OKAY]
utils .................. [NO] ....... [OKAY]
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/home/guodong.li/virtual-venv/llama-venv-py310-cu117/lib/python3.10/site-packages/torch']
torch version .................... 1.13.1+cu117
deepspeed install path ........... ['/home/guodong.li/virtual-venv/llama-venv-py310-cu117/lib/python3.10/site-packages/deepspeed']
deepspeed info ................... 0.8.0, unknown, unknown
torch cuda version ............... 11.7
torch hip version ................ None
nvcc version ..................... 11.7
deepspeed wheel compiled w. ...... torch 1.12, cuda 11.3
```


## 预安装DeepSpeed的Ops

> 注意：在预编译任何 DeepSpeed 的 c++/cuda ops 之前，必须先安装 PyTorch。但是，如果使用 ops 的默认 JIT 编译模式，则不需要预编译安装。


有时我们发现，将一些或全部 DeepSpeed C++/CUDA ops 预先安装而不使用 JIT 编译路径是有用的。为了支持预安装，我们引入了构建环境标志以打开/关闭特定 ops 的构建。

您可以通过设置 DS_BUILD_OPS 环境变量为 1 来指示我们的安装程序（install.sh 或 pip install）尝试安装所有 ops，例如：

DS_BUILD_OPS=1 pip install deepspeed

DeepSpeed 只会安装与你的机器兼容的 ops。有关系统兼容性的更多详细信息，请尝试上面描述的 ds_report 工具。

如果你只想安装特定的 op（例如 FusedLamb），你可以在安装时使用 DS_BUILD 环境变量进行切换。例如，要仅安装带有 FusedLamb op 的 DeepSpeed，请使用：
```
DS_BUILD_FUSED_LAMB=1 pip install deepspeed
```

可用的 DS_BUILD 选项包含：
```
DS_BUILD_OPS 切换所有 ops
DS_BUILD_CPU_ADAM 构建 CPUAdam op
DS_BUILD_FUSED_ADAM 构建 FusedAdam op (from apex)
DS_BUILD_FUSED_LAMB 构建 FusedLamb op
DS_BUILD_SPARSE_ATTN 构建 sparse attention op
DS_BUILD_TRANSFORMER 构建 transformer op
DS_BUILD_TRANSFORMER_INFERENCE 构建 transformer-inference op
DS_BUILD_STOCHASTIC_TRANSFORMER 构建 stochastic transformer op
DS_BUILD_UTILS 构建各种优化工具
DS_BUILD_AIO 构建异步 (NVMe) I/O op
```
为了加速 build-all 过程，您可以使用以下方式并行编译：

DS_BUILD_OPS=1 pip install deepspeed --global-option="build_ext" --global-option="-j8"

这应该可以使完整的构建过程加快 2-3 倍。您可以调整 -j 来指定在构建过程中使用多少个 CPU 核心。在此示例中，它设置为 8 个核心。

你还可以构建二进制 wheel，并在具有相同类型的 GPU 和相同软件环境（CUDA 工具包、PyTorch、Python 等）的多台机器上安装它。

DS_BUILD_OPS=1 python setup.py build_ext -j8 bdist_wheel

这将在 dist 目录下创建一个 PyPI 二进制轮，例如 dist/deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl，然后你可以直接在多台机器上安装它，在我们的示例中：

```
pip install dist/deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl
```

## 源码安装 DeepSpeed
在从 GitHub 克隆 DeepSpeed 仓库后，您可以通过 pip 在 JIT 模式下安装 DeepSpeed（见下文）。由于不编译任何 C++/CUDA 源文件，此安装过程应该很快完成。


```
pip install .
```

对于跨多个节点的安装，我们发现使用 github 仓库中的 install.sh (https://github.com/microsoft/DeepSpeed/blob/master/install.sh) 脚本安装 DeepSpeed 很有用。这将在本地构建一个 Python whell，并将其复制到你的主机文件（通过 --hostfile 给出，或默认为 /job/hostfile）中列出的所有节点上。

当使用 DeepSpeed 的代码首次运行时，它将自动构建仅运行所需的 CUDA 扩展，并默认将它们放置在 ~/.cache/torch_extensions/ 目录下。下一次执行相同的程序时，这些已预编译的扩展将从该目录加载。

如果你使用多个虚拟环境，则可能会出现问题，因为默认情况下只有一个 torch_extensions 目录，但不同的虚拟环境可能使用不同的设置（例如，不同的 python 或 cuda 版本），然后加载另一个环境构建的 CUDA 扩展将失败。因此，如果需要，你可以使用 TORCH_EXTENSIONS_DIR 环境变量覆盖默认位置。因此，在每个虚拟环境中，你可以将其指向一个唯一的目录，并且 DeepSpeed 将使用它来保存和加载 CUDA 扩展。

你还可以在特定运行中更改它，使用：

```
TORCH_EXTENSIONS_DIR=./torch-extensions deepspeed ...
```



## 选择正确的架构进行构建
如果你在运行 DeepSpeed 时遇到以下错误：
```
RuntimeError: CUDA error: no kernel image is available for execution on the device
```
这意味着 CUDA 扩展没有为你尝试使用的卡构建。

从源代码构建 DeepSpeed 时，DeepSpeed 将尝试支持各种架构，但在 JIT 模式下，它只支持在构建时可见的架构。

你可以通过设置 TORCH_CUDA_ARCH_LIST 环境变量来专门为所需的一系列架构构建：
```
TORCH_CUDA_ARCH_LIST="6.1;7.5;8.6" pip install ...
```

当你为更少的架构构建时，这也会使构建更快。

这也是为了确保使用你的确切架构而建议的。由于各种技术原因，分布式的 PyTorch 二进制文件没有完全支持所有架构，跳过兼容的二进制文件可能会导致未充分利用你的完整卡的计算能力。要查看 deepspeed 来源构建中包含哪些架构 - 保存日志并搜索 -gencode 参数。

完整的 NVIDIA GPU 列表及其计算能力可以在这里 (https://developer.nvidia.com/cuda-gpus) 找到。



## CUDA 版本不匹配
如果在运行时碰到以下错误：

```
Exception: >- DeepSpeed Op Builder: Installed CUDA version {VERSION} does not match the version torch was compiled with {VERSION}, unable to compile cuda/cpp extensions without a matching cuda version.
```

你安装的 CUDA 版本与用于编译 torch 的 CUDA 版本不匹配。我们仅需要主版本匹配（例如，11.1 和 11.8 是可以的）。但是，主版本不匹配可能会导致意外的行为和错误。

解决此错误的最简单方法是更改已安装的 CUDA 版本（使用 nvcc --version 检查）或更新 torch 版本以匹配已安装的 CUDA 版本（使用 python3 -c "import torch; print(torch.version)" 检查）。

如果你想跳过此检查并继续使用不匹配的 CUDA 版本，请使用以下环境变量：

```
DS_SKIP_CUDA_CHECK=1
```

## 针对特定功能的依赖项

一些 DeepSpeed 功能需要 DeepSpeed 的一般依赖项之外的特定依赖项。

有关每个功能/op 的 Python 包依赖项，请参阅我们的 requirements 目录（https://github.com/microsoft/DeepSpeed/tree/master/requirements）。

我们尽力将系统级依赖项最小化，但某些功能需要特殊的系统级软件包。请查看我们的 ds_report 工具输出，以查看您是否缺少给定功能的系统级软件包。









