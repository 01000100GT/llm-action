


- https://pytorch.org/tutorials/intermediate/ddp_series_multinode.html



多节点训练涉及在多台机器上部署训练作业。 有两种方法可以做到这一点：

- 在每台机器上使用相同的rendezvous参数运行 torchrun 命令
- 使用工作负载管理器（如：SLURM）将其部署在计算集群上

在本视频中，我们将介绍从单节点多 GPU 迁移到多节点训练所需的（最小）代码更改，并以上述两种方式运行我们的训练脚本。

请注意，多节点训练受到节点间通信延迟的瓶颈。在单个节点上的 4 个 GPU 上运行训练作业比在 4 个节点（每个节点有 1 个 GPU）上运行训练作业要快。


## Local 和 Global ranks


在单节点设置中，我们跟踪运行训练过程的每个设备的 gpu_id。 torchrun 在环境变量 LOCAL_RANK 中跟踪该值，该变量
唯一标识节点上的每个 GPU 进程。 对于所有节点上的唯一标识符，torchrun 提供了另一个变量 RANK，它指的是进程的全局排名（ranks）。



警告

不要将 RANK 用于训练工作中的关键逻辑。 当 torchrun 在失败或成员数更改后重新启动进程时，无法保证进程将保持相同的 LOCAL_RANK 和 RANKS。



## 异构扩展

Torchrun 支持异构扩展，即每台多节点机器可以有不同数量的 GPU 参与训练作业。 在视频中，我将代码部署在 2 台机器上，其中一台机器有 4 个 GPU，另一台机器仅使用 2 个 GPU。


## 故障排除

确保您的节点能够通过 TCP 相互通信。

将环境变量 NCCL_DEBUG 设置为 INFO（使用导出 NCCL_DEBUG=INFO）以打印有助于诊断问题的详细日志。

有时您可能需要显式设置分布式后端。参考：https://pytorch.org/docs/stable/distributed.html#choosing-the-network-interface-to-use







