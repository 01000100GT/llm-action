



- https://pytorch.org/docs/stable/distributed.html


# Backends



## 常用环境变量

选择要使用的网络接口

默认情况下，NCCL 和 Gloo 后端都会尝试找到要使用的正确网络接口。 

如果自动检测到的接口不正确，您可以使用以下环境变量覆盖它（适用于各自的后端）：

- NCCL_SOCKET_IFNAME，例如：export NCCL_SOCKET_IFNAME=eth0
- GLOO_SOCKET_IFNAME，例如：export GLOO_SOCKET_IFNAME=eth0


如果您使用的是 Gloo 后端，则可以通过用逗号分隔来指定多个接口，如下所示：export GLOO_SOCKET_IFNAME=eth0,eth1,eth2,eth3。 后端将以循环方式跨这些接口调度操作。

所有进程必须在此变量中指定相同数量的接口。

其他 NCCL 环境变量

- 调试 - 如果 NCCL 失败，您可以设置 NCCL_DEBUG=INFO 来打印显式警告消息以及基本 NCCL 初始化信息。

您还可以使用 NCCL_DEBUG_SUBSYS 来获取有关 NCCL 特定方面的更多详细信息。 

例如，NCCL_DEBUG_SUBSYS=COLL 将打印collective调用的日志，这在调试挂起时可能会有所帮助，特别是那些由collective类型或消息大小不匹配引起的情况。

如果拓扑检测失败，设置 NCCL_DEBUG_SUBSYS=GRAPH 将有助于检查详细的检测结果并保存以供需要 NCCL 团队进一步帮助时参考。

- 性能调优 - NCCL根据其拓扑检测进行自动调优，以节省用户的调优工作。 在某些基于socket的系统上，用户仍然可以尝试调整 NCCL_SOCKET_NTHREADS 和 NCCL_NSOCKS_PERTHREAD 以增加socket网络带宽。 NCCL 已针对某些云提供商（例如：AWS 或 GCP）预先调整了这两个环境变量。

NCCL环境变量的完整列表，请参考NVIDIA NCCL的官方文档：https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/env.html


# Basics


torch.distributed 包为在一台或多台机器上运行的多个计算节点之间的多进程并行提供了 PyTorch 支持和通信原语。 

torch.nn.parallel.DistributedDataParallel() 类基于此功能构建，提供同步分布式训练作为任何 PyTorch 模型的包装器。 这与 Multiprocessing 包 - torch.multiprocessing 和 torch.nn.DataParallel() 提供的并行不同，因为它支持多个网络连接的机器，并且用户必须为每个机器显式启动主训练脚本的单独副本进程。

在单机同步情况下，torch.distributed 或 torch.nn.parallel.DistributedDataParallel() 包装器可能仍然比其他数据并行方法（包括 torch.nn.DataParallel()）具有优势：

- 每个进程都维护自己的优化器，并在每次迭代时执行完整的优化步骤。 虽然这可能看起来多余，但由于梯度已经被收集在一起并在进程之间求平均值，因此对于每个进程都是相同的，这意味着不需要参数广播步骤，从而减少了在节点之间传输张量所花费的时间。

- 每个进程都包含一个独立的 Python 解释器，消除了从单个 Python 进程驱动多个执行线程、模型副本或 GPU 带来的额外解释器开销和“GIL 颠簸”（GIL-thrashing）。 这对于大量使用 Python 运行时的模型尤其重要，包括具有循环层或许多小组件的模型。

















