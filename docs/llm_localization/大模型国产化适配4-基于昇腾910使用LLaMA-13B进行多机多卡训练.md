

随着 ChatGPT 的现象级走红，引领了AI大模型时代的变革，从而导致 AI 算力日益紧缺。与此同时，中美贸易战以及美国对华进行AI芯片相关的制裁导致 AI 算力的国产化适配势在必行。之前讲述了**基于昇腾910使用ChatGLM-6B进行模型训练和推理**，本文主要针对 MindSpore 和 Pytorch 分布式 AI 框架在进行多机多卡训练（双机16卡），为了文章具有更好的阅读体验，具体代码放置在GitHub：[llm-action](https://github.com/liguodongiot/llm-action/tree/main/train/mindformers/chatglm)。




## 数据

本文采用斯坦福羊驼提供的数据集进行训练：[下载地址](https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json)。该数据集是利用OpenAI提供的GPT模型API生成质量较高的指令数据。然而，Alpaca 格式不适合用于多轮对话。参考 Vicuna 进行多轮对话训练的数据集格式，下面使用 [`alpaca_converter.py`](https://gitee.com/mindspore/mindformers/tree/8eec953/mindformers/tools/dataset_preprocess/llama) 脚本添加 prompts 模板，同时，转换为多轮对话格式。


转换前：

```json
[
    {
        "instruction": "Give three tips for staying healthy.",
        "input": "",
        "output": "1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n2. Exercise regularly to keep your body active and strong. \n3. Get enough sleep and maintain a consistent sleep schedule."
    },
    {
        "instruction": "What are the three primary colors?",
        "input": "",
        "output": "The three primary colors are red, blue, and yellow."
    },
]
```

转换后：

```json
[
   {
     "id": "1",
     "conversations": [
       {
         "from": "human",
         "value": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Response:"
       },
       {
         "from": "gpt",
         "value": "1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n2. Exercise regularly to keep your body active and strong. \n3. Get enough sleep and maintain a consistent sleep schedule."
       }
     ]
   },
   {
     "id": "2",
     "conversations": [
       {
         "from": "human",
         "value": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nWhat are the three primary colors?\n\n### Response:"
       },
       {
         "from": "gpt",
         "value": "The three primary colors are red, blue, and yellow."
       }
     ]
   },
]
```




## 使用 MindSpore 进行多机多卡训练

### 环境

- **操作系统版本/架构**：EulerOS release 2.0 (SP8)/aarch64
- **NPU**：8卡 910B 64G
- **Python**：3.7.5
- **NPU 驱动**：23.0.rc1，[下载](https://www.hiascend.com/zh/hardware/firmware-drivers/community?product=2&model=19&cann=6.3.RC1.alpha003&driver=1.0.19.alpha)
- **NPU 固件**：6.3.0.1.241，[下载](https://www.hiascend.com/zh/hardware/firmware-drivers/community?product=2&model=19&cann=6.3.RC1.alpha003&driver=1.0.19.alpha)
- **CANN 工具包**：6.3.RC1.alpha003，[下载](https://www.hiascend.com/software/cann/community-history)
- **MindSpore**：2.1.0
- **MindFormers**：dev


安装 MindFormers（MindSpore Transformers 的简称）。









### 训练


首先，在每台服务器上面生成用于Ascend芯片分布式通信的芯片资源信息配置文件（RANK_TABLE_FILE）。Ascend 
HCCL 的 RANK_TABLE_FILE 文件提供Ascend分布式训练作业的集群信息。


然后，合并每个机器上的RANK_TABLE_FILE文件。可以使用官网提供的脚本`merge_hccl.py`进行合并，也可以手动进行合并。


之后，将合并后的RANK_TABLE_FILE文件分别复制到所有的机器上。



接下来，根据服务器节点数等信息，修改相应的配置。



最后，在每一台服务器上面运行训练脚本。



## 使用 Pytorch 进行多机多卡训练







### 环境

- **操作系统版本/架构**：EulerOS release 2.0 (SP8)/aarch64
- **NPU**：8卡 910B 64G
- **Python**：3.7.5
- **NPU 驱动**：23.0.rc1，[下载](https://www.hiascend.com/zh/hardware/firmware-drivers/community?product=2&model=19&cann=6.3.RC1.alpha003&driver=1.0.19.alpha)
- **NPU 固件**：6.3.0.1.241，[下载](https://www.hiascend.com/zh/hardware/firmware-drivers/community?product=2&model=19&cann=6.3.RC1.alpha003&driver=1.0.19.alpha)
- **CANN 工具包**：6.3.RC1.alpha003，[下载](https://www.hiascend.com/software/cann/community-history)
- **Pytorch**：1.11.0
- **Huggingface Transformers**：4.28.1
- **DeepSpeed**：0.6.0


安装PyTorch和PyTorch插件torch_npu。

```
# 安装1.11.0版本
wget https://repo.huaweicloud.com/kunpeng/archive/Ascend/PyTorch/torch-1.11.0-cp37-cp37m-linux_aarch64.whl
# 安装1.11.0版本
pip3 install torch-1.11.0-cp37-cp37m-linux_aarch64.whl

# 安装1.11.0版本
pip3 install torch_npu-1.11.0-cp37-cp37m-linux_aarch64.whl
```


安装Apex。
```
yum install -y patch libjpeg-turbo-devel dos2unix openblas git 
# gcc 7.3.0版本及以上，cmake 3.12.0版本及以上。若用户要安装1.11.0版本PyTorch，则gcc需为7.5.0版本以上。
yum install -y gcc==7.3.0 cmake==3.12.0 

# 获取昇腾适配的APEX源码。
git clone -b master https://gitee.com/ascend/apex.git


# 进入昇腾适配的APEX源码目录，获取原生APEX代码。
cd apex
git clone https://github.com/NVIDIA/apex.git


# 进入原生APEX代码目录，切换对应分支。
cd apex 
git checkout 4ef930c1c884fdca5f472ab2ce7cb9b505d26c1a 
cd .. 

# 在昇腾适配的APEX源码目录下的scripts中执行命令生成NPU适配的全量代码。
cd scripts
bash gen.sh


进入原生APEX执行命令编译生成二进制安装包。
cd ../apex
python3 setup.py --cpp_ext --npu_float_status bdist_wheel

# 执行如下命令安装。如果使用非root用户安装，需要在命令后加--user。
cd dist
pip3 install apex-0.1_ascend-cp37-cp37m-linux_aarch64.whl
```



安装 Huggingface Transformers。
```
pip3 install --upgrade pip
pip3 install einops sympy regex decorator scipy setuptools scm prompt toolkit
```


```
git clone https://gitee.com/ascend/ModelZoo-PyTorch.git
cd ModelZoo-PyTorch/PyTorch/built-in/foundation/LLaMA-13B
pip3 install -e .
```

安装 DeepSpeed 以及 Ascend NPU 适配 DeepSpeed 的插件。

```
pip3 install deepspeed==0.6.0 

git clone https://gitee.com/ascend/DeepSpeed.git
cd DeepSpeed
python setup.py develop
```

替换transformers库中相关文件。将源码包根目录下`transformers_modify`文件夹中的各个文件分别替换到transformers 安装目录下的对应位置（基于transformers 4.28.1版本）：

```
training_args.py -> transformers/training_args.pu
trainer.py -> transformers/trainer.py
versions.py -> utils/versions.py
modeling_llama.py -> transformers/models/llama/modeling_llama.py
```








### 训练



首先，生成用于Ascend芯片分布式通信的芯片资源信息配置文件（RANK_TABLE_FILE）。Ascend 
HCCL 的 RANK_TABLE_FILE 文件提供Ascend分布式训练作业的集群信息。






















