


## 领域技术标准文档或领域相关数据是领域模型Continue PreTrain的关键。

现有大模型在预训练过程中都会加入书籍、论文等数据，那么在领域预训练时这两种数据其实也是必不可少的，主要是因为这些数据的数据质量较高、领域强相关、知识覆盖率（密度）大，可以让模型更适应考试。当然不是说其他数据不是关键，比如领域相关网站内容、新闻内容都是重要数据，只不过个人看来，在领域上的重要性或者知识密度不如书籍和技术标准。


## 领域数据训练后，往往通用能力会有所下降，需要混合通用数据以缓解模型遗忘通用能力。

如果仅用领域数据进行模型训练，模型很容易出现灾难性遗忘现象，通常在领域训练过程中加入通用数据。那么这个比例多少比较合适呢？目前还没有一个准确的答案，BloombergGPT（从头预训练）预训练金融和通用数据比例基本上为1:1，ChatHome（继续预训练）发现领域：通用数据比例为1:5时最优。个人感觉应该跟领域数据量有关，当数据量没有那多时，一般数据比例在1:5到1:10之间是比较合适的。


## 领域模型Continue PreTrain时可以同步加入SFT数据，即MIP，Multi-Task Instruction PreTraining。

预训练过程中，可以加下游SFT的数据，可以让模型在预训练过程中就学习到更多的知识。例如：T5、ExT5、Glm-130b等多任务学习在预训练阶段可能比微调更有帮助。并且ChatHome发现MIP效果在领域上评测集上绝群。

## 仅用SFT做领域模型时，资源有限就用在Chat模型基础上训练，资源充足就在Base模型上训练。（资源=数据+显卡）

跟很多人讨论过一个问题，就是我们在SFT的时候是在Base模型上训练还是在Chat模型上训练。

其实很简单，如果你只有5k数据，建议你在Chat模型上进行微调；如果你有10w数据，建议你在Base模型上进行微调。因为你不知Chat模型在SFT时的数据质量如何，当自己有能力时，靠人不如靠己。


## 在Chat模型上进行SFT时，请一定遵循Chat模型原有的系统指令&数据输入格式。

如果你在Chat模型上进行SFT的时候，请跟Chat模型的输入格式一致，否则当你数据量不足时，可能会导致训练效果不明显。并且建议不采用全量参数训练，否则模型原始能力会遗忘较多。


## 领域模型词表扩增是不是有必要的。

个人感觉，领域词表扩增真实解决的问题是解码效率的问题，给模型效果带来的提升可能不会有很大。（这里领域词表扩充是指在同语言模型上扩充词表，而不是英文模型的中文汉化）


## 领域评测集时必要内容，建议有两份，一份选择题形式自动评测、一份开放形式人工评测。

一定要有自己的领域数据集来验证模型效果，来选择最好的checkpoint。选择题形式可以自动评测，方便模型进行初筛；开放形式人工评测比较浪费时间，可以用作精筛，并且任务形式更贴近真实场景。
