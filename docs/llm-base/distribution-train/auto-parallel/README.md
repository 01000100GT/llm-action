



北大河图大模型自动并行训练工具Galvatron：https://zhuanlan.zhihu.com/p/591924340

大模型的自动并行之难主要体现在以下三个方面：

（1）多样性：首先，在并行方式方面，目前大模型的并行方式呈现出百花齐放的态势，
即使是对于同一个算子，不考虑混合并行方式，不同的基础并行方式也会存在显著的差异，从而导致不同的内存开销、通信代价以及计算效率。
其次，在模型方面，各种各样的模型架构最近也是层出不穷，这往往也伴随着不同的模型配置（例如不同输入序列长度，模型层数，模型隐层宽度等），从而造成计算负载上的差异。
另外，在硬件方面，用户往往面临着非常差异化的集群环境，可能会面临不同的内存容量、通信带宽、计算能力等等。
总体上来看，由于上述多样性的存在，没有哪种并行技术总是能够获得最佳训练效率，“自动并行”也就成为了分布式训练的核心挑战。

（2）复杂性：上述分析还相对比较单一，实际上哪怕是对于同一个算子也可以同时应用多种不同的基础并行方式，
如果考虑到由这些基础并行方式复合所构成的混合并行方式，则会导致问题变得非常复杂。
更重要的是，大模型的计算图往往结构非常庞大，对应的也需要更大规模的集群，如果对每个算子都进行探索（包括选取集群中合适的计算资源以及设计相应的混合并行方式），
会带来组合空间爆炸的问题，寻找整个模型的最优分布式执行方案变得难以求解。


（3）实用性：除此之外，实用性也是非常重要的问题。
一方面，在进行自动并行搜索的过程中，对于各种分布式执行方案，必须提供比较精确的内存、通信、计算开销，
否则会导致结果与实际执行偏差过大，产生次优解或者根本无法使用。
为此，就需要非常精准的代价模型，对不同的模型结构和硬件条件进行建模。
另一方面，系统提供自动并行能力所带来的额外时间开销必须在一个可以接受的范围内，过于高昂的搜索代价同样也无法接受。







