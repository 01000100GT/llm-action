





## 模型对比


| 模型    | GPT-2 XL（1.5B）          | Bloomz-7b1-mt | LLaMA-7B      | LLaMA2-7B       |
| ---- | ---------- | ----- | ------------------- | ----------- |
| 词表大小（vocab_size）  | 50257     |  250880 |  32000 |   32000    |
| Transformer层（n_layer）  | 48     | 30  | 32  |    32   |
| 隐藏层大小（hidden-size）  | N/A       |  N/A  | 4096  |     4096      |
| （ffn-hidden-size，intermediate_size）      | N/A   | N/A    | 11008 |   11008       |
| 注意力头数（num-attention-heads，n_head）      | 25      | 32  | 32 |   32       |
| 注意力头数（num-attention-heads，n_head）      | 25      | 32  | 32 |   32       |




