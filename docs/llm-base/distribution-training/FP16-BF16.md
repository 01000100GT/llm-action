




## FP16


数值上溢和数值下溢的问题

数值上溢：大量级的数被近似为正无穷或负无穷时发生上溢，进一步运算导致无限值变为非数字。

数值下溢：接近零的数被四舍五入为0时发生下溢。被零除，取零的对数，进一步运算会变为非数字。



求梯度的时候可能下溢，求激活的时候可能上溢出。


### 存在的问题

使用FP16同样会带来一些问题，其中最重要的是1）精度溢出和2）舍入误差。


数据溢出：可见FP16相比FP32的有效范围要窄很多，使用FP16替换FP32会出现上溢（Overflow）和下溢（Underflow）的情况。而在深度学习中，需要计算网络模型中权重的梯度（一阶导数），因此梯度会比权重值更加小，往往容易出现下溢情况。


舍入误差：Rounding Error指示是当网络模型的反向梯度很小，一般FP32能够表示，但是转换到FP16会小于当前区间内的最小间隔，会导致数据溢出。

如0.00006666666在FP32中能正常表示，转换到FP16后会表示成为0.000067，不满足FP16最小间隔的数会强制舍入。







