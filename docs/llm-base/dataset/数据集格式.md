




## Alpaca



仅支持单轮对话（alpaca_data.json）：

```
{
    "instruction": "Give three tips for staying healthy.",
    "input": "",
    "output": "1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n2. Exercise regularly to keep your body active and strong. \n3. Get enough sleep and maintain a consistent sleep schedule."
}
```



- https://github.com/tatsu-lab/stanford_alpaca/blob/main/train.py#L127


```
dict(input_ids=self.input_ids[i], labels=self.labels[i])
```


## FastChat（Vicuna）

- 参考：https://github.com/lm-sys/FastChat/blob/ec9a07ed22110e9686b51fd6ee9bf635b7ce54f8/fastchat/conversation.py


单轮对话（alpaca-data-conversation.json）：

```
{
"id": "1",
"conversations": [
  {
    "from": "human",
    "value": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Response:"
  },
  {
    "from": "gpt",
    "value": "1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n2. Exercise regularly to keep your body active and strong. \n3. Get enough sleep and maintain a consistent sleep schedule."
  }
]
}
```

多轮对话（dummy_conversation.json）：

```
{
"id": "identity_2",
"conversations": [
  {
    "from": "human",
    "value": "What is up?"
  },
  {
    "from": "gpt",
    "value": "Hello! How can I help you today?"
  },
  {
    "from": "human",
    "value": "Who are you?"
  },
  {
    "from": "gpt",
    "value": "You can call me Vicuna, and I was trained by Large Model Systems Organization (LMSYS) researchers as a language model."
  },
  {
    "from": "human",
    "value": "Goodbye"
  },
  {
    "from": "gpt",
    "value": "Goodbye! If you have any more questions in the future, don't hesitate to ask."
  }
]
}
```


## ChatGLM3

参考：
- https://github.com/THUDM/ChatGLM3/blob/main/PROMPT.md
- https://github.com/THUDM/ChatGLM3/tree/main/finetune_chatmodel_demo
- https://github.com/tangqiaoyu/ToolAlpaca




单轮对话（参考Alpaca）：

```
{"context": "hello", "target": "hi,I am ChatGLM3"}
```

其中，context是对话的上文，也就是模型的输入，target是对话的下文，也就是模型的输出。


基座模型不支持对话，工具，代码生成等能力，仅支持文本生成。如果你需要对话能力，请使用Chat模型和对应的微调框架。


- https://github.com/THUDM/ChatGLM3/blob/main/finetune_chatmodel_demo/preprocess_utils.py#L112

InputOutputDataset

```
{
    "input_ids": input_ids,
    "labels": labels
}
```



多轮对话：


ChatGLM3 对话的格式由若干对话组成，其中每个对话包含对话头和内容，一个典型的多轮对话结构如下：


```
<|system|>
You are ChatGLM3, a large language model trained by Zhipu.AI. Follow the user's instructions carefully. Respond using markdown.
<|user|>
Hello
<|assistant|>
Hello, I'm ChatGLM3. What can I assist you today?
```

实际中每轮对话内容并不一定以换行符结尾，这里只是为了美观。


多轮（仅对话）：


```
[
  {
    "conversations": [
      {
        "role": "system",
        "content": "<system prompt text>"
      },
      {
        "role": "user",
        "content": "<user prompt text>"
      },
      {
        "role": "assistant",
        "content": "<assistant response text>"
      }, 
       // ... Muti Turn
      {
        "role": "user",
        "content": "<user prompt text>"
      },
      {
        "role": "assistant",
        "content": "<assistant response text>"
      }
    ]
  }
  // ...
]
```




多轮（对话+工具）：

```json
[
   {
      "tools": [
         // available tools, format is not restricted
      ],
      "conversations": [
         {
            "role": "system",
            "content": "<system prompt text>"
         },
         {
            "role": "user",
            "content": "<user prompt text>"
         },
         {
            "role": "assistant",
            "content": "<assistant thought to text>"
         },
         {
            "role": "tool",
            "name": "<name of the tool to be called",
            "parameters": {
               "<parameter_name>": "<parameter_value>"
            },
            "observation": "<observation>"
            // don't have to be string
         },
         {
            "role": "assistant",
            "content": "<assistant response to observation>"
         },
         // ... Muti Turn
         {
            "role": "user",
            "content": "<user prompt text>"
         },
         {
            "role": "assistant",
            "content": "<assistant response text>"
         }
      ]
   }
   // ...
]
```




- https://github.com/THUDM/ChatGLM3/blob/main/finetune_chatmodel_demo/preprocess_utils.py#L82

MultiTurnDataset

```
{
    "input_ids": tokens,
    "labels": labels
}
```



## Baichuan2



参考：

```
 {
  "id": "77771",
  "conversations": [
   {
    "from": "human",
    "value": "写一篇关于气候变化对海洋生态的影响的文章。\n"
   },
   {
    "from": "gpt",
    "value": "好的，以下是你要求的文章：\n气候变化对海洋生态的影响\n气候变化对海洋生态产生了广泛的影响。全球变暖导致海洋温度上升，这可能会对许多水生生物的生存、繁殖和迁移造成巨大的影响。另外，海洋酸化也是一个问题，因为大气中二氧化碳的增加导致海水中的pH值下降，使得许多生物的外骨骼变得脆弱，从而影响它们的生存和繁殖。\n此外，气候变化还会引起海平面上升，这不仅对海岸线和沿海居民产生影响，还会对许多海洋生物的栖息地造成影响。一些岛屿上的陆地生物面临几乎完全消失的风险，而另一些生物范围则会扩大到更广泛的领域，这可能会导致新的竞争和生态平衡的改变。\n总之，气候变化并不只是一个地球气温的问题，它对海洋生态系统产生了广泛和深远的影响。\n"
   },
   {
    "from": "human",
    "value": "从刚刚的文章中提取出气候变化对海洋生物繁殖的影响。\n"
   },
   {
    "from": "gpt",
    "value": "文章已经提到过气候变化会对海洋生物的生存、繁殖和迁移造成影响。例如，海洋酸化会使得许多生物的外骨骼变得脆弱，进而影响它们的生存和繁殖。此外，海洋温度上升也可能会对很多生物的生存和繁殖产生负面影响。"
   }
  ]
 }
```



- https://github.com/baichuan-inc/Baichuan2/blob/main/fine-tune/fine-tune.py#L70

```
def preprocessing(self, example):
	return {
        "input_ids": input_ids,
        "labels": labels,
        "attention_mask": attention_mask,
    }
```


## ModelScope-Agent


参考：
- https://github.com/modelscope/modelscope-agent
- https://modelscope.cn/datasets/damo/MSAgent-Bench/summary

MSAgent-Bench数据集主要包括了四种：AI模型API，通用API，API无关通用sft数据，API检索增强数据



```
{
    "id":"modelscope_merge_api_527",
    "conversations":[
        {
            "from":"system",
            "value":"你是达摩院的ModelScopeGPT（魔搭助手），你是个大语言模型， 是2023年达摩院的工程师训练得到的。你有多种能力，可以通过插件集成魔搭社区的模型api来回复用户的问题，还能解答用户使用模型遇到的问题和模型知识相关问答。1. {\"plugin_name\": \"modelscope_text-ie\", \"plugin_owner\": \"ModelScopeGPT\", \"plugin_type\": \"default\", \"plugin_schema_for_model\": {\"name\": \"modelscope_text-ie\", \"description\": \"针对中文的文本，根据schema要抽取的内容，找出其中对应信息，并用json格式展示\", \"url\": \"http://109.199.101.10:1485/\", \"paths\": [{\"name\": \"modelscope_text-ie\", \"model_id\": \"/damo/nlp_structbert_siamese-uie_chinese-base\", \"method\": \"post\", \"description\": \"针对中文的文本，根据schema要抽取的内容，找出其中对应信息，并用json格式展示\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本\", \"required\": \"True\"}, {\"name\": \"schema\", \"description\": \"要抽取信息的json表示\", \"required\": \"True\"}]}]}}\n\n2. {\"plugin_name\": \"modelscope_text-ie\", \"plugin_owner\": \"ModelScopeGPT\", \"plugin_type\": \"default\", \"plugin_schema_for_model\": {\"name\": \"modelscope_text-ie\", \"description\": \"针对中文的文本，根据schema要抽取的内容，找出其中对应信息，并用json格式展示\", \"url\": \"http://9.32.64.200:5873/\", \"paths\": [{\"name\": \"modelscope_text-ie\", \"model_id\": \"/damo/nlp_structbert_siamese-uie_chinese-base\", \"method\": \"post\", \"description\": \"针对中文的文本，根据schema要抽取的内容，找出其中对应信息，并用json格式展示\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本\", \"required\": \"True\"}, {\"name\": \"schema\", \"description\": \"要抽取信息的json表示\", \"required\": \"True\"}]}]}}\n\n3. {\"plugin_name\": \"modelscope_text-ie\", \"plugin_owner\": \"ModelScopeGPT\", \"plugin_type\": \"default\", \"plugin_schema_for_model\": {\"name\": \"modelscope_text-ie\", \"description\": \"针对中文的文本，根据schema要抽取的内容，找出其中对应信息，并用json格式展示\", \"url\": \"http://54.149.78.185:3979/\", \"paths\": [{\"name\": \"modelscope_text-ie\", \"model_id\": \"/damo/nlp_structbert_siamese-uie_chinese-base\", \"method\": \"post\", \"description\": \"针对中文的文本，根据schema要抽取的内容，找出其中对应信息，并用json格式展示\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本\", \"required\": \"True\"}, {\"name\": \"schema\", \"description\": \"要抽取信息的json表示\", \"required\": \"True\"}]}]}}"
        },
        {
            "from":"user",
            "value":"按照给定的schema抽取出下面文本对应的信息\nschema：{\"人物\": null, \"地理位置\": null, \"组织机构\": null}\n近日，美国政府宣布将对中国1000多种商品加征关税，并威胁进一步加征关税。"
        },
        {
            "from":"assistant",
            "value":"<|startofthink|>```JSON\n{\"api_name\": \"modelscope_text-ie\", \"url\": \"http://9.32.64.200:5873/damo/nlp_structbert_siamese-uie_chinese-base\", \"parameters\": {\"text\": \"近日，美国政府宣布将对中国1000多种商品加征关税，并威胁进一步加征关税。\", \"schema\": \"{\\\"人物\\\": null, \\\"地理位置\\\": null, \\\"组织机构\\\": null}\"}}\n```<|endofthink|>\n\n<|startofexec|>```JSON\n{\"人物\": [], \"地理位置\": [\"中国\", \"美国\"], \"组织机构\": []}\n```<|endofexec|>\n信息抽取结果：{\"人物\": [], \"地理位置\": [\"中国\", \"美国\"], \"组织机构\": []}。我使用的模型是ModelScope的'damo/nlp_structbert_siamese-uie_chinese-base'模型。这是一个基于StructBERT预训练模型微调训练的通用信息抽取模型。"
        }
    ]
}
```

数据格式说明：

id和converstions两个字段，其中conversations里面包含了system，user，assistant三种字段。其中：

- system: 表示给模型前置的人设输入，其中有告诉模型如何调用插件以及生成请求
- user: 表示用户的输入prompt，分为两种，通用生成的prompt和调用插件需求的prompt
- assistant: 为模型的回复。其中会包括插件调用代码和执行代码，调用代码是要LLM生成的，而执行代码是调用服务来生成结果的。
	- 比如：调用部分代码会通过<|startofthink|>和<|endofthink|>包起来，然后执行部分代码是api执行完结果后，把执行结果通过<|startofexec|>和<|endofexec|>包起来再输入给模型生成后面的回复


startofthink-endofthink：
```
{
	"api_name": "modelscope_text-ie",
	"url": "http://9.32.64.200:5873/damo/nlp_structbert_siamese-uie_chinese-base",
	"parameters": {
		"text": "近日，美国政府宣布将对中国1000多种商品加征关税，并威胁进一步加征关税。",
		"schema": "{\"人物\": null, \"地理位置\": null, \"组织机构\": null}"
	}
}
```

startofexec-endofexec：
```
{
	"人物": [],
	"地理位置": ["中国", "美国"],
	"组织机构": []
}
```





**推理链路搭建设计到LLM的推理和API的调用**

- 模型生成完整的<|startofthink|>和<|endofthink|>后，需要我们实时的去请求对应的API
- 返回结果后<|startofexec|>和<|endofexec|>拼接到现有的输入
- 然后再让大模型继续生成回复



- https://github.com/modelscope/modelscope-agent/blob/master/demo/tool_agent_finetune_swift/llm_sft.py
- https://github.com/modelscope/modelscope-agent/blob/master/demo/tool_agent_finetune_swift/utils/dataset.py#L18


```
def get_ms_tool_dataset(dataset_name_or_file) -> HfDataset:

	dataset = HfDataset.from_dict({
	    'inputs': all_inputs_str,
	    'flags': all_inputs_flag
	})
	return dataset
```


## QWen-Agent







## InternLM










