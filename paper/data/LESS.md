本文给大家分享一篇论文（LESS: Selecting Influential Data for Targeted Instruction Tuning），通过选择有影响力的少量数据进行目标指令调优。

以下是省流版：

## LESS 核心思想

LESS 核心思想通过仅给出的**少数体现特定能力的示例**，从大量指令数据集中**有效地选择5%有影响力的数据**用于目标任务的指令微调，其结果优于全量数据集进行微调，并且所选子集在不同模型参数规模和不同模型系列中仍然普遍有效。

**数据选择流水线**：

1. 使用 LoRA 进行热身训练，有利于后续获得有用的梯度特征。
2. 构建了一个**投影低维梯度特征**的**梯度数据存储**，可以重复用于不同的目标任务。
3. 利用**数据选择算法**使用存储梯度数据来构建训练数据集（少量有影响力的数据）。
4. 使用选择的数据训练模型。

**实验关键结果**：

1. **LESS 在不同的模型中都是有效的。**
2. **使用 LESS 选择 5% 的数据通常优于完整数据集进行训练**。
3. **使用小模型选择的数据可以提高较大的模型和不同模型的性能**。

**LESS 存在的局限性**：

1. 需要使用候选数据 D 的随机 5% 进行**热身训练**。这对于获得有用的梯度特征以进行数据选择至关重要，但**增加了 LESS 的复杂性和计算负载**。
2. 使用补全Token的平均梯度，这增加了较短训练序列的权重，从而导致性能明显变差。为了缓解这个问题，对 **LESS 中的梯度特征进行归一化，并使用余弦相似度而不是点积来估计影响**。
3. 最小化验证损失（即交叉熵损失）不会单调提高准确性。
4. 一阶近似**忽略了将多个数据点添加在一起的影响**。特别是，两个重复的点将获得同样高的分数，并被认为可以双重改进模型，但情况可能并非如此。

以下是完整版：

## 0. 摘要

LESS是一种优化器感知且实用和有效的算法，可**有效估计数据影响**并执行**低秩梯度相似性搜索**（Low-rankgradiEnt Similarity Search）以进行指令数据选择。更重要的是，LESS 兼容现有的影响力公式，以与 **Adam 优化器**和**可变长度指令数据**一起使用。

LESS 首先构建具有**低维梯度特征**的高度**可重用和可转移的梯度数据存储**，然后根据它们与**体现特定能力的少数示例数据**的**相似性**来选择有影响力的示例。

实验表明，在不同下游任务中，对选择的 5% 数据进行训练通常可以优于对完整数据集进行训练。此外，所选数据具有高度可转移性：即**可以利用较小的模型为较大的模型和来自不同系列的模型选择有用的数据**。通过定性分析表明，我们的方法超越了表面形式线索，**可以识别能够体现预期下游应用所需推理技能的数据**。

## 1. 简介

指令微调使得大语言模型善于遵循人类指令，成为多功能聊天机器人。然而了解如何最好地利用这些不同的数据集仍然是一个悬而未决的问题。

许多现实世界的应用程序要求训练LLMs中有一套特定能力（例如，推理技能）。然而，使用混合指令微调数据集训练 LLMs 可能会阻碍这些特定功能的开发。例如，在混合指令微调数据集上训练的 LLMs 表现出的性能比在数据子集上训练的性能更差。此外，考虑到广泛的用户查询以及响应这些查询所需的多种技能，可能**并不总是有足够的域内数据可用**。因此，我们希望能够**有效地利用通用指令微调数据来提高特定能力**。我们将此设置作为目标指令微调：

> 仅给出**少数体现特定能力的示例数据**，我们如何从大量指令数据集中有效地选择相关的微调数据？

我们通过对**最小化目标任务损失的数据**进行优先训练来解决这个问题，而不是依赖于表面形式特征。受到过去的工作**利用梯度信息估计单个训练数据点的影响**的启发，我们设计了一种**优化器感知方法**来选择此类数据。然而，这种影响力公式的直接应用面临着指令调优设置特有的几个挑战：

- 1. LLMs 传统上是**使用 Adam 优化器而不是**过去工作中考虑的**标准的 SGD 优化器**进行微调；
- 2. 使用可变长度指令数据的**序列级梯度可能会破坏影响估计**；
- 3. LLMs中大量的可训练参数使得**梯度的计算和存储极其消耗资源**。

我们在 LESS 中解决了这些问题，LESS 是一种执行**低秩梯度相似性搜索**来为目标应用程序选择相关指令微调数据的算法，它具有以下属性：

- **与 Adam 的指令微调兼容**：LESS 采用经典影响力公式中的梯度特征，同时与 Adam 优化器和可变长度指令数据配合使用。当然优化洞察（insights）和影响力公式也可能具有独立的意义。
- **高效**：LESS 使用 **LoRA 和随机投影**构建具有低维、易于计算梯度特征的**梯度数据存储**，从而允许高效且有效的数据集选择。梯度数据存储可以重复用于新的目标任务。
- **可转移**：使用小模型的梯度特征选择的数据会在大型模型和来自不同系列的模型中产生强大的性能，从而提高 LESS 的效率。
- **可解释**：定性分析表明，LESS 选择具有**相似推理和技能类型**的数据作为目标任务，而现有方法通常根据表面形式线索（例如：语言或主题）选择数据。

我们在三个不同的下游数据集（MMLU、TYDIQA 和 BBH）上评估我们的方法，每个数据集都包含不同的子任务，可以有效地模拟目标指令微调场景。

结果表明，LESS 通常会选择一小部分数据子集 (5%)，其性能优于整个数据集上的训练，并且所选子集在不同模型参数规模和模型系列中仍然普遍有效。

与其他数据选择方法的比较表明，**LESS 是唯一一致有效的方法**，证明其相对**较高的计算成本**是合理的。

## 2. 准备工作：影响力公式

使用训练时动态的一阶近似来**估计训练数据点对保留数据的影响**。

**每一步（step）的影响**。考虑一个模型 $\theta^t$ 在时间步$t$上训练损失 $\ell(\cdot;\theta)$ 。我们可以在验证数据点 $z'$ 上写出损失的一阶泰勒展开式：

$$
\ell(z';\theta^{t+1}) \approx \ell(z';\theta^t) + \langle\nabla\ell(z';\theta^t), \theta^{t+1}-\theta^t\rangle
$$

为了便于说明，假设我们使用批量大小为 $1$、学习率为 $\eta_t$ 的 SGD 来训练模型。如果 $z$  是时间步 t 的训练数据，我们可以将 SGD 更新写为 $\theta^{t+1} - \theta^t = -\eta_t \nabla\ell(z;\theta^t)$。那么泰勒展开式可以写为

$$
\ell(z';\theta^{t+1}) - \ell(z';\theta^t) \approx -\eta_t \langle\nabla\ell(z;\theta^t), \nabla\ell(z';\theta^t)\rangle
$$

**轨迹影响**。 z 对**整个训练运行的影响**可以通过聚合使用 z 的每个训练step的影响来测量。由于 z 被每个epoch使用一次，因此很自然地将其表示为epochs的总和：

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39b29be9b5624e989361030565cf0b41~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1008&h=164&s=32206&e=png&b=ffffff)

其中, $\bar\eta_i$是 N 个总训练epochs中第 i 个epoch期间使用的学习率。

Pruthi et al. (2020) 使用这种洞察（insights）来**识别错误标记的训练数据**，我们应用这个公式来**设计数据选择策略**。特别是，选择 z 来最大化

$$
\langle \nabla \ell(z';\theta^t), \nabla
\ell(z;\theta^t)\rangle
$$

 将**导致验证点 $z'$ 上的损失大幅减少**。值得注意的是，$z'$ 不一定与训练数据 z 直接相关，这使得该**数据选择策略在迁移学习设置中特别有用**。

接下来的两节描述我们如何采用这种基本方法通过指令微调来高效且有效地运行。

## 3. LESS：评估指令的影响力

在这里，我们描述 LESS 如何适应等式（1）中的影响力公式来选择有效促使目标能力的指令。我们在这里考虑两个主要的概念挑战：

- (1) 第 2 节中描述的过去的工作重点是使用 SGD 优化器，但 LLMs 传统上使用 Adam 进行调优。
- (2) **指令微调表现出异常梯度这导致先前的公式非常倾向于选择较短的指令，从而损害性能**。

> 我们遵循指令调优的标准自回归设置，其中，数据点z由指令s和补全c组成。对于每个数据点，损失为$\ell(z;\theta)$是模型分布$p(\cdot\vert s)$与真实标签c之间的交叉熵。当c包含多个tokens时，我们使用补全过程中token-wise交叉熵的平均值作为z的损失。我们使用$θ_t$表示第t步的模型，使用$θ_i$表示第i次训练之后的模型。

### 3.1. 扩展到 Adam 算法

等式 (1) 的公式是使用SGD优化模型所特有的。然而，指令调优通常使用 Adam 优化器进行。在这种情况下，给定步骤的参数更新为：

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8bb740adc4a548af98fef8cbb6fbd600~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1008&h=352&s=70543&e=png&b=ffffff)

其中,所有操作均按元素执行，$\beta_1$ 和 $\beta_2$分别作为一阶矩和二阶矩的超参数，$\epsilon$ 作为一个小常数。然后，Adam 动力学的一阶展开表明我们应该选择 z 来最大化 $\langle \nabla \ell(z';\theta^t), \Gamma(z;\theta^t)\rangle$。

然而，**使用此内积来测量轨迹影响需要在训练过程中访问模型梯度和优化器状态**。此外， $\Gamma(z;\theta)$  需要 m 和 v 项，这些项由先前的训练梯度确定。

总的来说，**这个公式使数据选择问题成为一个循环问题，因为每个点的影响取决于所选点的集合**。根据经验，我们可以通过在随机选择的完整数据集 D 的 5% 上运行 N = 4 个epochs的短期warmup训练来规避这些问题。我们在影响计算中使用本次运行的优化器状态作为$\Gamma(z;\theta_i)$。

### 3.2. 解决序列级梯度的异常问题

将第 2 节应用到指令微调设置中会认为示例 z 的梯度是补全c中每个Token的梯度的平均值。然后，我们将选择在每个序列中训练哪些Token，以便最好地减少验证损失。然而，估计单个Token的影响非常昂贵，因为它需要计算Token损失向量相对于模型参数的梯度，因此我们改为在序列级别执行数据选择。

由于示例梯度是许多 token 梯度的平均值，因此序列的**梯度范数**

$$
 ||\nabla
\ell(z;\theta^t)||
$$

**与补全c的长度负相关**（图 3 和图 4）。对于计算不同长度序列的平均Token梯度的影响公式来说，这是一个普遍问题。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b0f712cf9aea431c8eb780272f07c22a~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1058&h=527&s=117781&e=png&b=ffffff)

这种现象导致等式（1）中的影响大大**增加了较短训练序列的权重，这反过来又导致性能明显变差**（见表12）。为了缓解这个问题，我们对 **LESS 中的梯度特征进行归一化，并使用余弦相似度而不是点积来估计影响**。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a333bef24ad44d0e82f20c56ff394c18~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1059&h=279&s=83539&e=png&b=fefefe)

**公式 3.1 Adam Influence**：假设模型经过 N 个 epoch 的训练，其中  $\bar\eta_i$ 是第 i 个 epoch 的平均学习率，$\theta_i$ 是第 i 个 epoch 之后的模型检查点。当与Adam一起训练时，我们将训练数据点 $z$ 对验证数据点 $z'$ 的影响定义为

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/027e63a2848e4ccbb2b38db5bdcdabfd~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=866&h=188&s=42019&e=png&b=ffffff)

## 4. LESS：有效评估影响力

我们已经确定了如何**使用模型梯度来估计影响**，但考虑到 LLMs 的庞大规模，计算和存储模型梯度仍然非常昂贵。在本节中，将探讨**降低计算效率的设计**，并说明图 1 中的计算步骤。

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c5bc9064be344b597932284b26f3d68~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1068&h=341&s=139108&e=png&b=f8f7f7)

- 我们使用 LoRA 来有效地进行 warmup 训练，有利于后续获得有用的梯度特征。
- 然后，我们构建了一个**投影低维梯度特征**的**梯度数据存储**，可以重复用于不同的目标任务。
- 最后，我们详细介绍了我们的数据选择算法如何使用数据存储来构建训练数据集，以容纳目标验证集中的子结构（例如：推理技能）。

**设置**。我们的目标是大量、多样化的指令微调数据集 $D$ 中选择子集 $D_{train}$，以便在 $D_{train}$ 上训练模型可以在目标验证数据集 $D_{val}$ 上实现较低的损失，从而在测试数据上表现良好。 $D_{val}$ 可以包含多个子任务 $D_{val}^{(1)}, ..., D_{val}^{(m)}$（例如，多种语言的问答）。验证集是固定的，每个子任务仅包含几个示例（例如，TYDIQA 中每种语言 1 个示例）。我们使用保留的测试集 $D_{test}$ 来评估在 $D_{train}$ 上训练的模型的性能。

我们使用 $M_S$  表示用 $\theta$  参数化的模型，用于评分和选择数据；并使用 $M_T$  表示在所选数据上训练的模型。

**选择模型$M_S$不需要与目标模型$M_T$相同，在这种情况下，我们将该设置称为LESS-T**。

### 4.1. 高效的梯度特征计算

**计算定义公式 3.1** 需要计算两个向量的内积，其中可训练参数的大小为该模型。**直接使用这样的高维梯度向量作为数据集选择的特征在计算上非常昂贵**，因此我们**应用两种技术**来构造有意义的**低维梯度特征**：

通过 LoRA 进行参数高效微调和随机投影。我们将这些技术应用于 ∇ℓ(z′; θ) 来验证数据点 $z'$，并将这些技术应用于 Γ(z, θ) 来训练数据点 z。为了能够快速转移到新的目标验证任务，我们为候选训练数据点创建了一个具有这些低维特征的数据存储区。

第 1 步：**使用 LoRA 进行热身（Warmup）训练**。我们用LoRA减少可训练参数的数量并加速**定义 3.1** 中的内积计算。 LoRA 冻结预先训练的权重，并向整个网络的全连接层添加低秩适配器。我们使用 LoRA 在随机子集 $D_{warmup} ⊂ D$ 上对预训练的基础模型（例如： LLAMA-2-7B）进行 N 个epochs的指令调优，在每个epoch之后对模型进行checkpointing以存储 $\{\theta_i\}_{i=1}^N$。

使用 LoRA 训练时的梯度，表示为 $\hat{\nabla} \ell( . ;\theta) \in \R^{P}$
，比模型本身的维度低得多；例如，在 LLAMA-2-7B中，$\hat{\nabla} \ell(.;\theta)$ 小于 θ 大小的 2%。我们使用 $\hat{\nabla} \ell(.;\theta)$ 来计算 Adam 更新，并将其表示为$\hat{\Gamma} \ell(.,\theta)$。这种**初始热身训练**的动机是在第 3.1 节中，第 6.1 节中的经验结果表明，省略它会产生次优结果。

第 2 步：**投影梯度**。为了进一步降低特征维度，我们**对 LoRA 梯度应用随机投影**。 Johnson-Lindenstrauss 引理断言**此类投影通常保留定义 3.1 中的内积，从而确保这些低维梯度特征对于数据集选择仍然有用**。

对于给定的验证数据点 $z'$ 和模型检查点 $\theta_i$，我们可以计算 LoRA 梯度的 d 维投影 $\tilde{\nabla} \ell(z';\theta_i) = \Pi^\top \hat{\nabla} \ell(z';\theta_i) $，其中$\Pi \in \R^{P\times d}$的每个条目从 Rademacher 分布中绘制 (即$\Pi_{ij}\sim \mathcal{U}(\{-1,1\})$)。

对于训练数据点 z，我们计算$\tilde{\Gamma}({z} , {\cdot}) = \Pi^\top\hat{\Gamma}({z},{\cdot})$。我们使用内存高效在线随机投影实现去计算并应用  $\Pi$。实际上，我们选择 $d = 8192$。

### 4.2. 数据选择算法

数据选择策略（参见图 1 中的步骤 3）采用第 2 节中的方法来有效地操作验证集的子任务（例如：BigBench 中的各个任务）。对于每个子任务 D，我们计算每个模型检查点 $\theta_1,...,\theta_N$ 的平均梯度特征。

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3d7680804ef947e3975e472354859e3b~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=373&h=83&s=11303&e=png&b=ffffff)

如定义 3.1 所示，然后我们在整个训练过程中汇总给定数据点与每个验证子任务的接近程度的分数。例如，我们可以将定义3.1改写为

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/63101746f39b4f5f8b3ea267a97c623b~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=519&h=91&s=18036&e=png&b=ffffff)

我们选择可以提高任何一项验证子任务性能的训练数据点。按照公式2中的逻辑，我们计算 z 的分数作为所有子任务的最大值：$\max_j Inf_{Adam}(z, \mathcal{D} _{val}^{(j)})$
。我们选择得分最高的例子来构造$D_{train}$。选择后，我们使用选择的子集$D_{train}$来训练目标模型$M_T$。

## 5. 实验结果

### 5.1.实验装置

**训练数据集**。使用以下指令调优数据集：

(1) 从现有数据集创建的数据集，例如：FLAN V2 (Longpre
et al., 2023) and COT (Wei et al., 2022c)；

(2) 具有人工编写答案的开放式生成数据集，包括 DOLLY (Conover et al., 2023) 和 OPEN ASSISTANT。

这些数据集的格式和底层推理任务差异很大。训练数据集不包含目标查询的任何明显的域内数据。

**评估数据集**。我们在 MMLU (Hendrycks et al., 2020), TYDIQA (Clark et al.,2020) 和 BBH (bench authors, 2023) 上评估我们的方法。

MMLU 包含多项选择题，涵盖 57 个任务，包括初等数学、美国历史、计算机科学、法律等。

TYDIQA 是一个多语言问答数据集，包含 11 种类型不同的语言。给定一个问题和相关段落，该任务需要从段落中提取答案。

BBH 是 BIG-Bench 中用于评估推理能力的 27 项挑战性任务的集合。

表 1 包含有关这些任务的更多详细信息。每个数据集都包含多个子任务，每个子任务都带有少量示例。这些示例用作数据选择（第 4.2 节）的 $D_{val}$ 以及评估中的少量上下文学习演示。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/15e5e280980f4f35a44dda61f0880aff~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=536&h=205&s=36930&e=png&b=ffffff)

**用于数据选择和训练的模型**。我们测试LESS具有三个base模型：LLAMA-2-7B ，LLAMA-2-13B 和 MISTRAL-7B。在迁移设置（如：LESS-T）中，我们数据选择使用LLAMA-2-7B作为$M_s$，并训练LLAMA-
2-13B 或 MISTRAL-7B 作为目标模型 $M_T$ 。预热训练和最终模型训练均使用LoRA进行。我们的报告中使用了三个随机种子的平均性能和标准差。

**默认设置**。 LESS 对随机选择的完整数据集的 5% 进行 4 个 epoch 的预热训练，并计算数据 D 上的 8192 维梯度特征（第 4.1 节）。对于每个目标任务，我们使用这些特征根据其影响对数据点进行评分（定义 3.1）并选择$D$中得分最高的5%来构建$D_{train}$。我们在这个选定的数据$D_{train}$上训练目标模型$M_T$ 。

### 5.2.基线

我们将 LESS 与几个baseline进行比较。

最简单的baseline是**随机选择**，我们从训练集中随机采样数据以进行指令调优。

我们还与 BM25进行比较，后者通过词频统计（即 TF-IDF）来对示例进行特征化，以对训练实例进行排名。我们测量候选训练数据 D 和验证数据 $D_{val}$ 之间的相似度，并选择相关性得分最高的前 k 个数据点来构建 $D_{train}$。

另一个baseline是 DSIR，它使用 n-gram，然后根据这些估计的权重对数据进行采样以构造 $D_{train}$。

我们还与 RDS（基于表示的数据选择）进行比较，后者使用模型的隐藏表示作为数据选择的特征。

为了公平比较，我们使用等式（2）**计算相似度得分**，但用每个序列最后一个token的最后层表示替换梯度特征。这些特征在 LLAMA-2-7B 中是 2048 维的。我们考虑的另一个直观baseline直接**使用验证数据 $D_{val}$ 进行训练，但这会大大降低性能**。

### 5.3. 关键结果

- **LESS 在不同的模型中都是有效的**。表2显示在所有模型和评估数据集中，LESS 始终优于随机选择 2 到 5 个点，这表明我们的数据选择方法选择有用的数据进行微调。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bfd337ec2aea496a94a356c5a42692cd~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1059&h=312&s=118759&e=png&b=ffffff)

- **5% 的数据通常优于完整数据集**。在表 2，我们比较了使用 LESS 选择的 5% 数据进行的训练和使用完整数据集进行的训练。令人惊讶的是，我们发现在大多数情况下，仅使用 5% 的数据进行训练会比使用整个数据集产生更好的结果。我们假设**完整数据集包含与特定目标任务无关或有害的数据点**。当使用更强的基础模型（例如：LLAMA-2-13B 和 MISTRAL-7B）时，这种效果更加明显。

> 我们注意到，被丢弃的 95% 中可能仍然有有用的数据，我们将探索未来工作的最佳阈值。

- **使用小模型选择的数据可以提高较大和不同模型的性能**。表 2 评估了几种
  LESS-T 设置。我们使用 LLAMA-2-7B  作为选择数据的模型并训练 LLAMA-2-13B （即更大的模型）和 MISTRAL-7B (（即不同的模型系列）作为目标模型 $M_T$。LESS-T 优于随机选择，与LESS（即直接使用LLAMA-2-13B 或 MISTRAL-7B作为选择模型$M_S$）相比差距较小。 LESS-T 的强大性能表明 LESS 选择了普遍有用的数据，因此数据选择成本可以进一步摊销到不同的模型中。从概念上讲，我们在第 2 节中的推导指出，**当不同examples的梯度内积对于 $M_S$ 和  $M_T$ 大致相等时**，**使用一种模型选择的数据集会在另一种模型中产生强大的性能**。我们的实验证实这一发现是正确的，因此，在预训练和上下文学习中，小模型可以有效地为其他模型选择数据。
- **与其他 baseline 相比 LESS 是唯一持续有效的方法**：在表 3 中，我们将 LESS 与几个基线进行了比较。我们观察到依靠**词频统计**（例如：BM25）、n-gram 特征（例如：DSIR）或表示（例如：RDS）的传统方法相对于随机选择的改进很小，并且 LESS 始终优于最强的基线。我们承认基线方法的计算成本较低。尽管如此，我们的研究结果表明，**指令数据需要对数据点之间的相似性进行精确定义**（即，定义 3.1 中的影响力公式）。尽管基线方法通常选择与查询和补全在主题或语义上相似的数据，但定性分析（第 6.2 节）表明**LESS更擅长选择与目标任务$D_{val}$需要相同推理过程(即：指令如何执行)的数据**。

## 6. 分析

我们通过两种方式来分析 LESS。首先，我们详细介绍了 LESS 的计算成本，并探讨了不同的设计选择如何影响性能（第 6.1 节）。其次，我们提出了定性分析，表明了 LESS 选择了与目标任务所需的推理能力相符的数据（第 6.2 节）。

### 6.1. 计算复杂度

表 4 描述了 LESS 每一步所需的渐近复杂度、运行时间（wall-clock runtime）和存储成本。表中的运行时间以单个 A100 (80GB) GPU 小时来测量。**梯度特征计算是最昂贵的步骤**，并且成本与候选数据集大小 |D|、检查点数量 N 和梯度维度 d 线性增长。存储结果的梯度数据存储所消耗的内存与d成线性比例。热身训练也相对昂贵，并且复杂性随着 $|\mathcal{D}_{warmup}|$ 和 N 的变化而变化。然而，这两个阶段产生的费用是一次性成本，可以在许多目标任务中摊销。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8344565bcedd442ba7ec826cac303940~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1060&h=254&s=90139&e=png&b=ffffff)

在以下部分中，我们将探讨 $|\mathcal{D}_{warmup}|$ 、N 和 d 的选择如何影响 LESS 的性能。总之，增加 $\mathcal{D}_{warmup}$ 和 N 可以提高影响评估的准确性（定义 3.1），但这样做也会增加预热训练步骤的成本。同样，增加 d 可以提高投影梯度特征的效用，但这样做也会增加 LESS 所需的内存和计算量。

**热身训练至关重要**。热身训练步骤在 $\mathcal{D}_{warmup}$ 上微调模型，通常是数据 D 的随机 5%。我们调查：

- (1) 是否此步骤是必要的
- (2) 使用更多数据是否可以进一步提高性能。

对于（1），我们使用预训练的 LLAMA-2-7B 和 LLAMA-
2-7B-CHAT 作为选择模型来创建用于选择数据的梯度数据存储。表 5 表明，使用预训练的模型进行数据选择会严重损害LESS的性能。这一观察结果可能源于**输入分布的变化**，或者更一般地说，源于**训练动态中的细微差别**。我们将详细的调查留给未来的工作。

对于 (2)，我们将 $\mathcal{D}_{warmup}$ 的大小更改为 5%（默认值）、25% 和整个数据集并计算 $Inf_{adam}$。增加$\mathcal{D}_{warmup}$提高性能，证实了我们的假设，即更准确地估计  $Inf_{adam}$（定义 3.1）是有帮助的。因此，**预热阶段至关重要，但不需要太长的时间，LESS 就能产生强劲的性能**。

**更多检查点，更好的性能**。我们调查在热身训练阶段使用较少的检查点（即对定义 3.1 中较少的梯度特征进行求和）是否会影响 LESS 的性能。表 6 显示，仅使用一个 LoRA 检查点的性能优于随机选择，但低于使用四个检查点的性能。我们推测这是因为梯度特征在指令调优开始时发生了很大变化。

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/837fcde19b974c63b2957fe439a93e75~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=516&h=259&s=46708&e=png&b=ffffff)

**小的投影维度就足够了**。我们学习选择不同的梯度投影维度 d，特别是 1024、2048、4096 和 8192（默认），如何影响 LESS 的性能。图 2 显示，d 的所有选择都比随机选择提高了性能，并且随着 d 的增加，LESS 以更高的计算成本产生更强的性能（参见表 4）。

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39920516f9df48b899f6ea87ffaf3a4b~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=520&h=431&s=54333&e=png&b=ffffff)

### 6.2. 定性分析

我们手动比较 LESS 和 baseline 方法选择的数据。表 15 显示了 BM25、RDS 和 LESS 选择的top示例，给出了来自TYDIQA数据集的单个孟加拉语问答示例。

**BM25 和 RDS 只是简单的匹配少样本(few-shot)数据**$\mathcal{D}_{val}$，并从不同的任务中选择孟加拉语示例（掩模恢复和仇恨言论检测）。

相比之下，LESS 从类似于 TYDIQA 的开卷问答任务中选择英语示例。此示例表明，**LESS 选择具有相似底层推理类型的示例，而不会严重依赖表面文本或语言提示**。尽管使用不同的语言，此类示例仍然可以有效地零样本（zero-shot）迁移到孟加拉语。

此外，我们观察到LESS从DOLLY数据集中为TYDIQA选择了更多的例子，可能是因为DOLLY包含了许多开卷问答的例子。我们的研究结果表明，**LESS 可用于提高大型通用指令微调数据集的可解释性**。

## 7. 相关工作

### 7.1. 整理高质量的指令调优数据

使用高质量的指令调优数据可以显著提高 base LLMs。指令调优数据通常有两种类型：

- （1）从传统 NLP 任务中收集的基于任务的数据集
- （2）开放式指令遵循数据集，涵盖广泛的主题。

事实证明，**提高数据质量和多样性而不是数量可以更有效地诱导指令遵循能力**。我们的工作通过从大量可用数据集中选择高质量的相关数据来丰富这一叙述，以在模型中引入特定的能力。

### 7.2. 核心集和基于梯度的数据选择

数据集选择问题被视为核心集选择问题，**其目的是找到训练示例的子集，从而产生与完整数据集训练类似的性能**。通常这些工作侧重于**领域内核心集选择**，而我们的工作涉及**迁移学习**。

之前的几项工作使用预定义的有用数据概念或 n-gram 特征来选择预训练示例，但 LESS 更接近类似于对梯度信息的依赖。我们的工作最接近 Han et al. (2023)，它使用模型梯度来选择预训练数据以提高上下文学习性能。然而，我们的离线方法可以非常有效地适应新的下游任务。

### 7.3. 数据归因和影响函数

我们的影响力公式已被用于**识别错误标记**的例子、分析记忆效果以及得出各种可解释性见解，但它**不允许反事实推理**。

另一方面，影响力函数**可以对模型行为和训练数据进行反事实推理**，但一些研究发现其**鲁棒性和有效性存在局限性**。

在 LLM 场景中，影响力函数的计算成本很高，尽管一些并发工作提出**使用高效的影响力函数估计来选择预训练数据**。我们的研究结果表明，一阶影响力近似对于迁移学习环境中的数据选择是有效的。

## 8. 讨论和未来的工作

我们提出了一种**基于优化器感知影响力的数据选择算法** LESS。 LESS 创建了一个有效且可重用的低维梯度特征的数据存储，以实现高效的数据选择。第 5 节中的实验证明了 LESS 与相关基线相比的有效性，并强调了**使用较小模型选择数据来训练较大模型的能力**（表 2）。第 6 节中的分析和消融实验表明，我们的方法**选择了更多可解释的数据，但计算成本可能很高**。

将来，LESS 可以有效地用于测试时间自适应，使模型能够适应根据用户提供的上下文和示范来选择的数据。此外，我们可以**修改数据选择过程，以最小化任何可微分指标**（例如，毒性和危害性的替代指标），而**不仅仅是交叉熵损失**。此外，我们的实验发现可能会促使我们进一步研究**梯度特征在数据选择中的作用，而不是表面形式线索**。对优化特性和序列级梯度现象（第 3.2 节）的见解可能具有理论意义。

我们观察到，调**优更多数据会降低特定任务的性能，这也可能与 LLMs 中观察到的灾难性遗忘行为密切相关**。

## 9. 局限性

1. **需要热身训练阶段**。预热训练阶段对于获得有用的梯度特征以进行数据选择至关重要。显然，我们必须微调base模型以与我们打算选择的特定数据分布保持一致，因为直接利用 LLAMA-2-7B 或者 LLAMA-2-7B-CHAT 等预训练模型的梯度并不有效（表5）。这一额外步骤增加了 LESS 的复杂性和计算负载。
2. **使用补全Token的平均梯度**。 所有补全Token的平均梯度用作代表整个序列的代理。在训练或验证数据中涉及较长序列的场景中，例如：开放式生成，这种合并可能会变得更加模糊且效率较低。在第 3.2 节中，我们重点介绍了此操作如何导致数据选择流水线中出现异常。
3. **最小化损失不会单调提高准确性**。最小化验证损失（即交叉熵损失）并不总能提高指令调优中的任务性能。这是因为指令调优任务通常需要模型产生长格式的生成。尽管困惑度与base LLMs 中的任务表现非常一致，但在微调或指令调优中，这种关系更加模糊。 LESS 的动机是选择最小化验证损失的数据点（第 2 节），这种策略通常会产生高准确性模型（表 2），但最小化损失并不能单调提高准确性（见附录I，图 5 和图 6 ）。
4. **数据选择中的线性度**：第 2 节中的**一阶近似忽略了将多个数据点添加在一起的影响**。特别是，**两个重复的点将获得同样高的分数，并被认为可以双重改进模型，尽管情况可能并非如此**。 Saunshi et al. 的初步理论 (2023) 讨论了影响力何时可以线性增加，但总的来说，我们认为这种近似是 LESS 的限制。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/93dd482656de4175a9f73a5f726243bb~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1062&h=694&s=126386&e=png&b=fff9f9)

## 结语

本文介绍了一种数据选择的方法 LESS及其技术原理。

码字不易，如果觉得我的文章能够能够给您带来帮助，期待您的点赞收藏加关注~~

参考文档：

- 论文：LESS: Selecting Influential Data for Targeted Instruction Tuning
- 代码：https://github.com/princeton-nlp/LESS
