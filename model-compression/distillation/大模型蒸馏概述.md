

知识蒸馏（KD）是一种有价值的机器学习技术，旨在提高模型性能和泛化能力。

它通过将知识从复杂的模型（称为教师模型）转移到更简单的模型（称为学生模型）来实现这一点。 KD背后的核心思想是将教师模型的综合知识转化为更精简、更有效的表示。 




在本节中，我们概述了利用LLM作为教师的蒸馏方法。我们根据这些方法是否将LLM的涌现能力（EA）提炼成小语言模型（SLM）来对这些方法进行分类。 因此，我们将这些方法分为两个不同的类别：标准 KD 和基于 EA 的 KD。 为了直观地表示，图 2 提供了LLM知识蒸馏的简要分类。




Standard KD旨在使学生模型学习LLM所拥有的常见知识，如输出分布和特征信息。这种方法类似于传统的KD，但区别在于教师模型是LLM。 比如：MINILLM和GKD。


MINILLM 深入研究了白盒生成LLM的蒸馏。 它观察到最小化前向 Kullback-Leibler 散度 (KLD) 的挑战（这可能会导致教师分布中不太可能的区域出现概率过高，从而在自由运行生成过程中导致不可能的样本）。
为了解决这个问题，MINILLM 选择最小化反向 KLD。 这种方法可以防止学生高估教师分布中的低概率区域，从而提高生成样本的质量。



GKD 探索了自回归模型的蒸馏，这里白盒生成 LLM 是一个子集。 该方法确定了两个关键问题：训练期间的输出序列与学生在部署期间生成的输出序列之间的分布不匹配，以及模型under-specification，其中学生模型可能缺乏与教师分布相匹配的表达能力。

GKD 通过在训练期间对学生的输出序列进行采样来处理分布不匹配，它还通过优化替代分歧（反向 KL）来解决模型under-specification的问题。





--


基于 EA 的 KD 不仅仅迁移 LLM 的常识，还包括蒸馏他们的涌现能力。


与 BERT（330M）和 GPT-2（1.5B）等较小模型相比，GPT-3（175B）和 PaLM（540B）等 LLM 展示了独特的行为。 这些LLM在处理复杂的任务时表现出令人惊讶的能力，称为“涌现能力”。 涌现能力包含几个有趣的方面，包括上下文学习 (ICL)、思维链 (CoT) 和指令遵循 (IF)。 有关直观概述，请参阅图 3，它提供了基于EA的知识蒸馏概念的简明表示。



ICL 采用结构化自然语言提示，其中包含任务描述以及可能的一些任务示例作为演示。 

通过这些任务示例，LLM可以掌握并执行新任务，而无需显式梯度更新。 In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models 论文中引入了 ICL 蒸馏，它将上下文小样本学习和语言建模功能从 LLM 转移到 SLM。这是通过将上下文学习目标与传统语言建模目标相结合来实现的。

为了实现这一目标，他们在两种小样本学习范式下探索了 ICL 蒸馏：元上下文调优 (Meta-ICT) 和多任务上下文调优 (Multitask-ICT)。

在 Meta-ICT 中，语言模型使用上下文学习 objectives 在不同任务中进行元训练。这使其能够通过上下文学习来适应看不见的任务，从而扩展其解决问题的能力。

另一方面，Multitask-ICT 使用 ICL objectives 和target任务中的一些示例对模型进行微调。随后，它采用上下文学习来对这些任务进行预测。 比较这两种范式，Multitask-ICT 表现出优于 Meta-ICT 的性能。 然而，它在任务适应过程中确实需要更多的计算资源，使其计算加强。




与 ICL 相比，CoT 采用了不同的方法，它将中间推理步骤（可以导致最终输出）合并到提示中，而不是使用简单的输入输出对。

MT-COT [Li et al., 2022] 旨在利用LLM产生的解释来加强小型推理机的训练。它利用多任务学习框架使较小的模型具有强大的推理能力以及生成解释的能力。

Fine-tuneCoT [Ho et al., 2023] 更进一步，通过随机采样从 LLM 生成多个推理解决方案。 训练数据的增强有助于学生模型的学习过程。 

Fu 等人的研究发现语言模型的多维能力之间的权衡，并提出微调指令调整模型。 他们从大型教师模型中提取 CoT 推理路径，以提高分布外泛化能力。

Hsieh 等人使用LLM原理作为在多任务框架内训练较小模型的额外指导。

SOCRATIC CoT [Shridhar et al., 2023] 训练两个蒸馏模型：问题分解器和子问题求解器。 

分解器将原始问题分解为一系列子问题，而子问题求解器负责解决这些子问题。 

DISCO [Chen et al., 2023] 引入了一种基于LLM的全自动反事实知识蒸馏方法。 

它通过工程化的提示使用LLM生成短语扰动，然后通过特定于任务的教师模型过滤这些扰动，以提取高质量的反事实数据。 

为了保证基本原理的准确性，SCOTT [Wang et al., 2023a] 采用对比解码，将每个基本原理与答案联系起来。 它鼓励老师提出相关的理由。 此外，引导学生进行反事实推理，并根据导致不同答案的理由进行预测。




IF 致力于仅基于阅读任务描述来增强语言模型执行新任务的能力，而不依赖于少数样本。 通过使用一系列以指令表示的任务进行微调，语言模型展示了准确执行以前未见过的指令中描述的任务的能力。 

例如，Lion [Jiang et al., 2023] 利用LLM的适应性来提高学生模型的表现。 它
提示LLM识别并生成“hard”指令，然后利用这些指令来增强学生模型的能力。 这种方法利用了LLM的用途广泛的特性来指导学生模型的学习，以解决复杂的指令和任务。
















