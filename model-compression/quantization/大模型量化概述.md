











LLM-QAT [Liu等，2023] 利用预训练模型生成的结果来实现无数据蒸馏。此外，LLM-QAT不仅量化权重和激活，还量化了KV缓存。这个策略旨在增强吞吐量并支持更长的序列依赖。LLM-QAT能够将带有量化权重和KV缓存的LLaMA模型蒸馏为仅有4比特的模型。这一突破性的结果论证了生产准确的4比特量化的LLM的可行性。



---


PEQA [Kim等，2023]和QLORA [Dettmers等，2023a]都属于量化感知参数高效微调（PEFT）技术的范畴。这些技术侧重于促进模型压缩和加速推理。

PEQA采用了双阶段过程。在第一阶段，每个全连接层的参数矩阵被量化为低位整数矩阵和标量向量。在第二阶段，对每个特定下游任务的标量向量进行微调。

QLORA引入了新的数据类型、双重量化和分页优化器等创新概念。这些想法旨在在不影响性能的情况下节省内存。QLORA使得大型模型可以在单个GPU上进行微调，同时在Vicuna基准测试上实现了最先进的结果。

---

在PTQ中，某些方法专注于仅对LLM的权重进行量化，以提高效率并减少计算需求。
LUT-GEMM [Park等，2022]通过仅对权重进行量化以及使用BCQ格式在LLM中优化矩阵乘法，通过提高计算效率来增强延迟降低和性能。

LLM.int8() [Dettmers等，2022]对LLM transformers中的矩阵乘法采用8位量化，在推理过程中有效地减少GPU内存使用量，同时保持性能精度。该方法采用矢量量化和混合精度分解来处理异常值，以实现高效的推理。


ZeroQuant [Yao等，2022]将硬件友好的量化方案、逐层知识蒸馏和优化的量化支持整合在一起，将Transformer-based模型的权重和激活精度减少到最小的INT8，并且对准确性几乎没有影响。

GPTQ [Frantar等，2022]提出了一种基于近似二阶信息的新型分层量化技术，使得每个权重的比特宽度减少到3或4位，与未压缩版本相比，几乎没有准确性损失。

Dettmers和Zettlemoyer通过分析推理缩放定律，深入探讨了LLM中模型大小和位精度之间在零样本性能方面的权衡。他们在各种LLM家族之间进行了广泛的实验，发现4位精度几乎普遍是在总模型位数和零样本准确性之间实现正确平衡的最佳选择。

AWQ [Lin等，2023]发现对于LLM的性能，权重并不是同等重要的，仅保护1%的显著权重可以大大减少量化误差。在此基础上，AWQ采用了激活感知方法，考虑与较大激活幅度对应的权重通道的重要性，这在处理重要特征时起着关键作用。该方法采用逐通道缩放技术来确定最佳缩放因子，从而在量化所有权重的同时最小化量化误差。

OWQ [Lee等，2023]通过分析激活异常如何放大权重量化中的误差，引入了混合精度量化方案，将更高的精度应用于易受激活异常影响的权重。

SpQR [Dettmers等，2023b]确定并隔离了异常权重，将其存储在更高的精度中，并将所有其他权重压缩为3-4位。
此外，许多PTQ中的工作尝试对LLM的权重和激活进行量化。
SmoothQuant [Xiao等，2022]解决了量化激活的挑战，这往往由于异常值的存在而变得更加复杂。SmoothQuant观察到不同的标记在它们的通道上展示出类似的变化，引入了逐通道缩放变换，有效地平滑了幅度，使得模型更易于量化。

鉴于量化LLM中激活的复杂性，RPTQ [Yuan等，2023]揭示了不同通道之间不均匀范围的挑战，以及异常值的存在所带来的问题。为了解决这个问题，RPTQ将通道策略性地分组为簇进行量化，有效地减轻了通道范围的差异。此外，它将通道重排集成到层归一化操作和线性层权重中，以最小化相关的开销。

OliVe [Guo等，2023]进一步采用了outlier-victim对（OVP）量化，并在低硬件开销和高性能增益的情况下局部处理异常值，因为它发现异常值很重要，而其旁边的正常值却不重要。

Outlier Suppression+ [Wei等，2023]通过确认激活中的有害异常呈现出不对称分布，主要集中在特定通道中，引入了一种新的策略，涉及通道级的平移和缩放操作，以纠正异常的不对称呈现，并减轻问题通道的影响，并定量分析了平移和缩放的最佳值，同时考虑了异常的不对称性以及下一层权重引起的量化误差。

ZeroQuant-FP [Wu等，2023]探索了浮点（FP）量化的适用性，特别关注FP8和FP4格式。研究揭示，对于LLM，FP8激活在性能上持续优于INT8，而在权重量化方面，FP4在性能上与INT4相比具有可比性，甚至更优越。为了解决由权重和激活之间的差异引起的挑战，ZeroQuant-FP要求所有缩放因子为2的幂，并将缩放因子限制在单个计算组内。值得注意的是，ZeroQuant-FP还集成了Low Rank Compensation (LoRC) 策略，以进一步增强其量化方法的有效性。