










----


基于镜像：nvcr.io/nvidia/pytorch:23.10-py3


卸载镜像中原来的tensorrt

```
pip uninstall -y tensorrt
pip install mpi4py

```

安装CMake

```
ARCH=$(uname -m)
CMAKE_VERSION="3.24.4"

PARSED_CMAKE_VERSION=$(echo $CMAKE_VERSION | sed 's/\.[0-9]*$//')
CMAKE_FILE_NAME="cmake-${CMAKE_VERSION}-linux-${ARCH}"
RELEASE_URL_CMAKE=https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/${CMAKE_FILE_NAME}.tar.gz
wget --no-verbose ${RELEASE_URL_CMAKE} -P /tmp
tar -xf /tmp/${CMAKE_FILE_NAME}.tar.gz -C /usr/local/
ln -s /usr/local/${CMAKE_FILE_NAME} /usr/local/cmake

echo 'export PATH=/usr/local/cmake/bin:$PATH' >> "${BASH_ENV}"
```



安装tensorrt:

```
TENSOR_RT_VERSION="9.1.0.4"
CUDA_VERSION="12.2"

PY_VERSION=$(python -c 'import sys; print(".".join(map(str, sys.version_info[0:2])))')
PARSED_PY_VERSION=$(echo "${PY_VERSION//./}")

if [ -z "$RELEASE_URL_TRT" ];then
    ARCH=${TRT_TARGETARCH}
    if [ -z "$ARCH" ];then ARCH=$(uname -m);fi
    if [ "$ARCH" = "arm64" ];then ARCH="aarch64";fi
    if [ "$ARCH" = "amd64" ];then ARCH="x86_64";fi
    if [ "$ARCH" = "x86_64" ];then DIR_NAME="x64-agnostic"; else DIR_NAME=${ARCH};fi
    if [ "$ARCH" = "aarch64" ];then OS="ubuntu-22.04"; else OS="linux";fi
    RELEASE_URL_TRT=https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/secure/9.1.0/tars/tensorrt-${TENSOR_RT_VERSION}.${OS}.${ARCH}-gnu.cuda-${CUDA_VERSION}.tar.gz;
fi
wget --no-verbose ${RELEASE_URL_TRT} -O /tmp/TensorRT.tar
tar -xf /tmp/TensorRT.tar -C /usr/local/
mv /usr/local/TensorRT-${TENSOR_RT_VERSION} /usr/local/tensorrt
pip install /usr/local/tensorrt/python/tensorrt-*-cp${PARSED_PY_VERSION}-*.whl
rm -rf /tmp/TensorRT.tar
```

ENV LD_LIBRARY_PATH=/usr/local/tensorrt/lib:${LD_LIBRARY_PATH}



安装最新的Polygraphy：

```
RELEASE_URL_PG=https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/secure/9.0.1/tars/polygraphy-0.48.1-py2.py3-none-any.whl
pip uninstall -y polygraphy
pip install ${RELEASE_URL_PG}
```


安装 PyTorch 2.1：

ARG TORCH_INSTALL_TYPE="skip"

```
export _GLIBCXX_USE_CXX11_ABI=$1
export TORCH_CUDA_ARCH_LIST="8.0;9.0"

pip uninstall -y torch
cd /tmp
git clone --depth 1 --branch v$TORCH_VERSION https://github.com/pytorch/pytorch
cd pytorch
git submodule sync && git submodule update --init --recursive
pip install -r requirements.txt
python setup.py install
cd /tmp && rm -rf /tmp/pytorch
```

```
TORCH_VERSION="2.1.0"

pip install torch==${TORCH_VERSION}
```



```
https://github.com/NVIDIA/TensorRT-LLM/blob/v0.5.0/cpp/tests/CMakeLists.txt
```

- https://github.com/google/googletest



----





```
git clone https://github.com/NVIDIA/TensorRT-LLM.git
cd TensorRT-LLM
git submodule update --init --recursive
git lfs install
git lfs pull


docker pull nvcr.io/nvidia/pytorch:23.10-py3
```





```
https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/secure/9.1.0/tars/tensorrt-9.1.0.4.linux.x86_64-gnu.cuda-12.1.tar.gz;

https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/secure/9.1.0/tars/tensorrt-9.1.0.4.linux.x86_64-gnu.cuda-12.2.tar.gz

https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/secure/9.0.1/tars/polygraphy-0.48.1-py2.py3-none-any.whl
```





```
docker rm -f tensorrt_llm

docker run -dt --name tensorrt_llm \
--restart=always \
--gpus all \
--network=host \
--shm-size=4g \
-m 64G \
-v /home/gdong:/workspace \
-w /workspace \
nvcr.io/nvidia/pytorch:23.05-py3 \
/bin/bash


docker exec -it tensorrt_llm bash




pip install transformers==4.31.0 -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn


pip install transformers==4.31.0 --progress-bar off -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn
```




```
apt-get update && apt-get -y install git git-lfs

mkdir -p /workspace/local/tensorrt

python3 ./scripts/build_wheel.py --trt_root /workspace/local/tensorrt


```





## 错误信息


```
RuntimeError: can't start new thread
```

解决：

更新docker镜像







```
sed -i -e 's/^APT/# APT/' -e 's/^DPkg/# DPkg/' /etc/apt/apt.conf.d/docker-clean
```

