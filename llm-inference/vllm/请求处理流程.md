





从接收 request，到返回回复，大致的过程如下：

1 vllm 接收到 request 之后，会发放 request_uuid，并将 request 分配到 running, swap, waiting 三个队列当中。（参考 vllm.core.scheduler.Scheduler._schedule ）


2 根据用户等待的时间进行 request 优先级排序。从 running 和 swap队列中选择优先级高的 request 来生成对应的回复，由于 decoding 阶段，每次前项传播只预测一个 token，因此 vllm 在进行完一次前项传播（即 one decoding iteration）之后，会返回所有新生成的 tokens 保存在每个 request_uuid 下。（参考 vllm.engine.llm_engine.LLMEngine.step）

3 如果 request 完成了所有的 decoding 步骤，那么将其移除，并返回结果给用户。

4 更新 running, swap 和 waiting 的 request。

5 循环执行 2,3,4。








步骤 1：安排下一次迭代中要执行的序列以及要换入/换出/复制的Token块。

根据调度策略，序列可能被抢占/重新排序。
序列组（SG）是指由同一提示生成的一组序列。

步骤2：调用分布式执行器执行模型。

步骤3：处理模型输出。这主要包括：

解码相关输出。

根据采样参数（是否使用beam_search）使用模型输出更新计划的序列组。

释放已完成的序列组。

最后，它创建并返回新生成的结果。




抢占模式。
1. 交换(Swapping):将被抢占序列的块交换到CPU内存中，并在序列恢复时将它们交换回来。
2. 重计算(Recomputation):丢弃被抢占序列的块，并在恢复序列时重新计算它们，将序列视为新的提示。








